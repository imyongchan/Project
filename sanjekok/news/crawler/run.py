# run.py (SERVER)
import time
from .fetch import fetch_html
from .parse import parse_list_page, parse_detail_page
from .save import save_news
from datetime import datetime, timedelta

def crawl_news():
    print(f"\n===== ğŸŸ  ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘ (ì´ë¯¸ì§€ ì œì™¸) ğŸŸ  =====")

    one_year_ago = datetime.now() - timedelta(days=365)
    page = 1

    while True:
        print(f"\nâ–¶ ëª©ë¡ í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘...")

        try:
            list_url = (
                f"http://sanjaenews.co.kr/news/list.php?"
                f"&mcode=m641vf2&vg=&page={page}"
            )
            list_soup = fetch_html(list_url)
            articles = parse_list_page(list_soup)

            if not articles:
                print("ğŸŒ ê¸°ì‚¬ ì—†ìŒ â†’ ì¢…ë£Œ")
                break

        except Exception as e:
            print("âŒ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨:", e)
            break

        for art in articles:
            try:
                detail_soup = fetch_html(art["link"])
                detail = parse_detail_page(
                    detail_soup,
                    art.get("created_at_raw")
                )

                published_at = detail.get("published_at")
                if published_at and published_at < one_year_ago:
                    print("â¹ 1ë…„ ì´ì „ ê¸°ì‚¬ â†’ ì¢…ë£Œ")
                    return

                art["writer"] = detail.get("writer")

                # âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì•ˆ í•¨
                # ì›ë³¸ ì´ë¯¸ì§€ URL ê·¸ëŒ€ë¡œ ì €ì¥
                art["img_url"] = art.get("img_url")

                save_news(art)

            except Exception as e:
                print(f"âŒ ìƒì„¸ ì‹¤íŒ¨: {art['link']}", e)

            time.sleep(0.3)

        page += 1
        time.sleep(0.5)

    print("âœ… ë‰´ìŠ¤ í…ìŠ¤íŠ¸ í¬ë¡¤ë§ ì™„ë£Œ")
